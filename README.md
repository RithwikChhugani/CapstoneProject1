# YoGuru - Computer-based Yoga Assistant

#### Welcome to YoGuru. YoGuru is an AI Yoga Pose Instructor helping individuals practice yoga postures with best possible postures and at their own sweet time.
YoGuru is currently a console-based prototype consuming the `OpenPose API` to calculate angles between joints and distance between body points to give accurate suggestions for posture enhancement. The prototype successfully recognizes 2 postures: ***Warrior II & Extended Hand-To-Big-Toe***. The user can select between the two postures and perform it in front of their laptop webcam. The prototype is built keeping in mind the consumption via a laptop or a pc. 
To run the app, make sure all the dependencies are satisfied and your webcam is discoverable by the pc. Once up and running, you should see a window opened with your live camera feed, a stick figure imposed on your body and some suggestions helping you to get into the correct posture.

***Note***: 
> Make sure you unzip 2 rar files `models` and `tf_pose`.

> Make sure you are standing at a proper distance from your webcam showing your full body. 


## Abstract:
There has been an increasing trend of self-training for health benefits and Yoga is by far considered as one of the most effective form of exercises to enhance both mental and physical health. Researches have shown that Yoga could be a great cure for many diseases, mental illness. Yoga exercises help boost physical health as well as cleanse human body, mind and soul. Talking about peace, we could consider it as a secret weapon to battle against this pandemic. Everyone is trying to do something or the other to keep calm and make the most out of this current situation. Individuals have started practicing yoga learning from some video tutorials, online coaches etc., but learning yoga through available recorded videos won’t be able to give practioners feedbacks and if you go for a personal coach then that costs a lot of money. Yoguru is a project that helps recognize yoga exercise activities and gives suggestions for your postures to maximize health benefits and minimize potential injuries with the use of deep learning-based image classification and postures recognition model.

## Scope:
The scope of this project is to understand how OpenPose library work to construct human skeleton structures,  how to increase the accuracy of classification task with convolutional neural networks (CNNS) deep learning model.
The user streaming video will be taken as input to the model and then the posture will be recognized and classified. The classification tasks will be processed using OpenPose library and CNNs deep learning model. The suggestion system will give feedbacks based on the calculation of the skeleton structures compared with the predefined figures.

## Literature review
Health-related activities, especially sports and exercises have long been of interest to the general public. With the advancement in technology in general and the outbreak of artificial intelligent in specific, scientists and researchers have moved forward in developing tools and technologies that help athletes and trainers do their best in practice. For example, in soccer, Zhu et al. (2009) proposed a system that analyses the interaction between the ball and the players using spatial-temporal data from streaming video to identify the tactical patterns. Or like Chen et al. (2012) work on evaluating pitching in basketball, estimating shooting location in volleyball by tracking the ball motions in videos and providing its trajectory.
A great number of these works focus on proposing automated or semi-automated systems specialized in self-training that analyze and assist participants to improve their performance and avoid injuries in sports. With posture-based exercises like Yoga, it is very important to keep it right to avoid any potential injuries during practice. To address this problem, Patil et al. have proposed his “Yoga Tutor” project to detect the difference between the postures of trainers and professionals using the speeded up robust features (SURF). However, this model was considered unable to make appropriate comparison since it only uses the contour information.  Luo et al. introduced Yoga training system which utilized the Motion Replication Technique (MoRep) and an interface consisting of 16 Inertial Measurement Units (IMU) and 6 tactors, which directly affect how participants exercise. An image and text-based model is also proposed by Wu et al. to instruct trainers but it fails to analyze their postures.
Chen et al. introduced a computer assisted self-training system that uses star skeleton approach to acquire the descriptor for trainers’ poses. The project can classify 3 major postures: ‘tree, warrior III and downward facing dog’ at 82.84% of accuracy. Similar work with Deep learning approach was introduced by Shruti which can classify up to 6 yoga asanas at nearly perfect accuracy. Trejo et al. also proposed a model that classify 6 postures using Kinect depth camera, which is not generally available.
Using image recognition techniques, Mohanty et al. proposed a Yoga postures identifications system that make use of convolutional neural network (CNN) and stacked autoencoder (SEA) algorithms. The shortcoming of this system lies in the model that just process image input, not streaming video.
Since conventional skeleton extraction approaches involve high computational cost and are sensitive to noise, deep learning approaches have been introduced to replace them. DeepPose was one of the pioneer since it utilized the neural network regressors to do regression on coordinates of joints. It also gives prediction for the hidden parts of body to increase the model accuracy. However, this approach was limited by the localize problem.
OpenPose was introduced by Perceptual Computing Lab of Carnegie Mellon University as the first real-time multi-person system that jointly detect and describe the keypoints of human body, face, hand and foot on a single image. This library used the CMU Panoptic Studio dataset as training data and multi-stage convolutional neural networks (CNNs) architecture to identify a total of 135 joint keypoints on human body.



